{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b4eb416-7614-4457-8bd6-70120e87c39a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T05:43:24.580254Z",
     "iopub.status.busy": "2024-10-22T05:43:24.579134Z",
     "iopub.status.idle": "2024-10-22T05:43:24.594488Z",
     "shell.execute_reply": "2024-10-22T05:43:24.592884Z",
     "shell.execute_reply.started": "2024-10-22T05:43:24.580192Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, Trainer, TrainingArguments, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics import pairwise\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfa471a1-ac3f-49fe-b465-55ea7eb7b9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T05:26:34.187666Z",
     "iopub.status.busy": "2024-10-22T05:26:34.186813Z",
     "iopub.status.idle": "2024-10-22T05:26:34.201436Z",
     "shell.execute_reply": "2024-10-22T05:26:34.200614Z",
     "shell.execute_reply.started": "2024-10-22T05:26:34.187624Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextEmbeddingDataset(Dataset):\n",
    "    def __init__(self, texts, emb_g, emb_s):\n",
    "        \"\"\"\n",
    "        :param texts: List of original input texts.\n",
    "        :param emb_g: Embeddings from encoder g.\n",
    "        :param emb_s: Embeddings from encoder s.\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.emb_g = emb_g\n",
    "        self.emb_s = emb_s\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'text': self.texts[idx],\n",
    "            'emb_g': torch.tensor(self.emb_g[idx], dtype=torch.float32),\n",
    "            'emb_s': torch.tensor(self.emb_s[idx], dtype=torch.float32),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34d138d0-6568-4726-8462-1e764b8934f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T05:26:34.703768Z",
     "iopub.status.busy": "2024-10-22T05:26:34.702820Z",
     "iopub.status.idle": "2024-10-22T05:26:34.716431Z",
     "shell.execute_reply": "2024-10-22T05:26:34.715257Z",
     "shell.execute_reply.started": "2024-10-22T05:26:34.703694Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlignmentModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(AlignmentModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, emb_s):\n",
    "        return self.linear(emb_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6278bcb-b34e-4706-bc66-c017db2efb94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T05:26:37.068512Z",
     "iopub.status.busy": "2024-10-22T05:26:37.066989Z",
     "iopub.status.idle": "2024-10-22T05:26:37.083883Z",
     "shell.execute_reply": "2024-10-22T05:26:37.082194Z",
     "shell.execute_reply.started": "2024-10-22T05:26:37.068436Z"
    }
   },
   "outputs": [],
   "source": [
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def forward(self, aligned_emb_s, emb_g):\n",
    "        cos_sim = nn.functional.cosine_similarity(aligned_emb_s, emb_g, dim=-1)\n",
    "        loss = 1 - cos_sim.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e5cae50-0a2a-4ea5-bada-301364d029bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T05:26:39.492759Z",
     "iopub.status.busy": "2024-10-22T05:26:39.491809Z",
     "iopub.status.idle": "2024-10-22T05:26:39.510739Z",
     "shell.execute_reply": "2024-10-22T05:26:39.509558Z",
     "shell.execute_reply.started": "2024-10-22T05:26:39.492715Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoder_decoder(\n",
    "    model_name: str, lora: bool = False\n",
    ") -> transformers.AutoModelForSeq2SeqLM:\n",
    "    model_kwargs: Dict[str, Any] = {\n",
    "        \"low_cpu_mem_usage\": True,\n",
    "    }\n",
    "    if lora:\n",
    "        model_kwargs.update(\n",
    "            {\n",
    "                \"load_in_8bit\": True,\n",
    "                \"device_map\": \"auto\",\n",
    "            }\n",
    "        )\n",
    "    return transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_name, **model_kwargs\n",
    "    )\n",
    "\n",
    "def load_tokenizer(name: str, max_length: int) -> transformers.PreTrainedTokenizer:\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        name,\n",
    "        padding=\"max_length\",\n",
    "        truncation=\"max_length\",\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Disable super annoying warning:\n",
    "    # https://github.com/huggingface/transformers/issues/22638\n",
    "    tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def load_embedder_and_tokenizer(name:str, **kwargs):\n",
    "    model_kwargs = {\n",
    "        \"low_cpu_mem_usage\": True,  # Not compatible with DeepSpeed\n",
    "        \"output_hidden_states\": False,  # True output hidden states, for embedding last and first .\n",
    "    }\n",
    "    # TODO: check the configurations for commercial models\n",
    "\n",
    "    if name==\"me5\":\n",
    "        model = transformers.AutoModel.from_pretrained(\"intfloat/multilingual-e5-base\", **model_kwargs)\n",
    "        tokenizer = transformers.AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-base\")\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    else:\n",
    "        print(f\"WARNING: Trying to initialize from unknown embedder {name}\")\n",
    "        model = transformers.AutoModel.from_pretrained(name, **model_kwargs)\n",
    "        tokenizer = transformers.AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "72bb8602-c834-4e6d-ada7-70e88d2c068c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:20.350848Z",
     "iopub.status.busy": "2024-10-22T06:53:20.349190Z",
     "iopub.status.idle": "2024-10-22T06:53:20.364021Z",
     "shell.execute_reply": "2024-10-22T06:53:20.362678Z",
     "shell.execute_reply.started": "2024-10-22T06:53:20.350788Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_encoder_embeddings(model, tokenizer, input_texts):\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in input_texts:\n",
    "            inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "            outputs = model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze(0).numpy()  # Use mean pooling\n",
    "            embeddings.append(embedding)\n",
    "            print(embedding.shape)\n",
    "\n",
    "    return torch.tensor(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6eb45780-a22e-47d8-9c80-df7cde66c864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:00.541469Z",
     "iopub.status.busy": "2024-10-22T06:53:00.540081Z",
     "iopub.status.idle": "2024-10-22T06:53:00.558130Z",
     "shell.execute_reply": "2024-10-22T06:53:00.557253Z",
     "shell.execute_reply.started": "2024-10-22T06:53:00.541399Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_bleu(predictions, references):\n",
    "    bleu_metric = evaluate.load('sacrebleu')\n",
    "    return bleu_metric.compute(predictions=predictions, references=[[ref] for ref in references])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2d7d4e53-31b9-4b35-8316-be6827fe3739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:01.462577Z",
     "iopub.status.busy": "2024-10-22T06:53:01.461374Z",
     "iopub.status.idle": "2024-10-22T06:53:01.475978Z",
     "shell.execute_reply": "2024-10-22T06:53:01.474752Z",
     "shell.execute_reply.started": "2024-10-22T06:53:01.462508Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "\"This is a test sentence.\",\n",
    "\"I love natural language processing.\",\n",
    "\"Transformers are amazing models!\"\n",
    "]\n",
    "\n",
    "# Load embeddings from encoder g and encoder s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d619854c-50fe-4c58-9705-b8b3a20747f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:03.090878Z",
     "iopub.status.busy": "2024-10-22T06:53:03.090075Z",
     "iopub.status.idle": "2024-10-22T06:53:05.832464Z",
     "shell.execute_reply": "2024-10-22T06:53:05.832022Z",
     "shell.execute_reply.started": "2024-10-22T06:53:03.090838Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_model_name = \"intfloat/multilingual-e5-small\"\n",
    "encoder_decoder_model_name = \"google-t5/t5-small\"\n",
    "encoder, encoder_tokenizer = load_embedder_and_tokenizer(\"me5\")\n",
    "encoder_decoder = load_encoder_decoder(encoder_decoder_model_name)\n",
    "encoder_decoder_tokenizer = load_tokenizer(encoder_decoder_model_name, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "202ceea8-d49e-4a66-a745-cc55a4f285eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:22.932946Z",
     "iopub.status.busy": "2024-10-22T06:53:22.932028Z",
     "iopub.status.idle": "2024-10-22T06:53:22.993340Z",
     "shell.execute_reply": "2024-10-22T06:53:22.992897Z",
     "shell.execute_reply.started": "2024-10-22T06:53:22.932903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "(512,)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "emb_g = get_encoder_embeddings(encoder_decoder.encoder, encoder_decoder_tokenizer, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dfea815c-b6c8-4891-afbe-7f361b9b6d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:23.351202Z",
     "iopub.status.busy": "2024-10-22T06:53:23.350381Z",
     "iopub.status.idle": "2024-10-22T06:53:23.358272Z",
     "shell.execute_reply": "2024-10-22T06:53:23.357206Z",
     "shell.execute_reply.started": "2024-10-22T06:53:23.351159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6d658d2a-a3ce-484d-a6cb-996063f7f7ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:23.892455Z",
     "iopub.status.busy": "2024-10-22T06:53:23.890701Z",
     "iopub.status.idle": "2024-10-22T06:53:24.008890Z",
     "shell.execute_reply": "2024-10-22T06:53:24.008401Z",
     "shell.execute_reply.started": "2024-10-22T06:53:23.892387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "(768,)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "emb_s = get_encoder_embeddings(encoder, encoder_tokenizer, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "72a13e8d-76ae-428d-84ec-fa5d58c30685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:24.584188Z",
     "iopub.status.busy": "2024-10-22T06:53:24.583641Z",
     "iopub.status.idle": "2024-10-22T06:53:24.602924Z",
     "shell.execute_reply": "2024-10-22T06:53:24.602052Z",
     "shell.execute_reply.started": "2024-10-22T06:53:24.584150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aeaaa0e1-bc44-4a6b-8d36-d830ee248da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:25.105203Z",
     "iopub.status.busy": "2024-10-22T06:53:25.104055Z",
     "iopub.status.idle": "2024-10-22T06:53:25.117437Z",
     "shell.execute_reply": "2024-10-22T06:53:25.116282Z",
     "shell.execute_reply.started": "2024-10-22T06:53:25.105141Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TextEmbeddingDataset(texts, emb_g, emb_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0d468ba2-7ada-47b3-b8c1-d703e838a7bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:26.010422Z",
     "iopub.status.busy": "2024-10-22T06:53:26.008420Z",
     "iopub.status.idle": "2024-10-22T06:53:26.043628Z",
     "shell.execute_reply": "2024-10-22T06:53:26.042991Z",
     "shell.execute_reply.started": "2024-10-22T06:53:26.010355Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bj/qp6k2wl11h5gpn8j4hg0tgf40000gn/T/ipykernel_47549/3274619231.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'emb_g': torch.tensor(self.emb_g[idx], dtype=torch.float32),\n",
      "/var/folders/bj/qp6k2wl11h5gpn8j4hg0tgf40000gn/T/ipykernel_47549/3274619231.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'emb_s': torch.tensor(self.emb_s[idx], dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'This is a test sentence.',\n",
       " 'emb_g': tensor([-4.8239e-02,  1.6047e-02, -9.7561e-03, -1.6206e-02, -1.9525e-02,\n",
       "          6.1420e-02, -2.6809e-02, -3.9371e-02, -1.1036e-01, -1.2500e-01,\n",
       "         -1.3804e-02,  1.4954e-01,  4.1940e-02, -2.5307e-02, -1.1941e-02,\n",
       "          7.8106e-02, -3.2313e-02,  2.0682e-02,  4.1168e-02, -4.3143e-02,\n",
       "          2.5930e-02,  1.3033e-01,  1.4260e-01, -1.1514e-01,  8.2676e-02,\n",
       "         -1.0572e-01, -1.2880e-01, -1.2978e-01,  1.3664e-01, -2.0178e-01,\n",
       "          1.3683e-01,  1.4738e-02, -1.1337e-01, -8.0304e-03, -1.3763e-01,\n",
       "         -1.5196e-02,  5.1717e-02, -7.9046e-02, -1.8986e-01,  7.7120e-02,\n",
       "         -8.5474e-02,  5.5013e-03,  1.7629e-01, -1.2956e-01, -3.2731e-02,\n",
       "          1.0586e-01,  9.0880e-02, -1.5749e-02, -3.5015e-02,  2.3650e-02,\n",
       "          6.6901e-02, -6.6957e-02,  1.4793e-02,  1.0112e-01, -2.1416e-01,\n",
       "         -9.0710e-03,  6.3410e-02,  2.6716e-02, -3.7014e-02, -1.3567e-01,\n",
       "          1.0831e-02,  1.7049e-01,  3.2329e-01,  6.2452e-02, -1.7684e-01,\n",
       "         -8.2271e-02, -6.4568e-02, -1.4252e-01,  9.2385e-02,  1.3828e-01,\n",
       "         -5.4433e-02, -1.3342e-02,  3.3499e-02,  5.7482e-02, -6.7334e-02,\n",
       "          8.0594e-02,  5.6460e-03,  3.5231e-02,  4.2834e-02, -8.4002e-02,\n",
       "         -6.3577e-02, -9.6137e-02, -5.4491e-02,  5.3654e-02,  1.8640e-02,\n",
       "          1.2992e-01, -7.1322e-02, -1.5584e-01,  3.7837e-02, -6.1992e-02,\n",
       "          1.1245e-04,  4.1899e-02, -4.4860e-02,  3.4022e-02,  4.0016e-03,\n",
       "         -5.1100e-02,  5.4882e-02, -3.0934e-02, -1.8079e-01, -1.3226e-01,\n",
       "         -6.1073e-02,  5.7847e-02,  1.7913e-03,  1.0339e-01, -4.0251e-02,\n",
       "          3.3602e-02, -1.9932e-02, -3.6239e-02,  6.2246e-02,  2.3936e-02,\n",
       "          1.3488e-02,  7.1677e-03, -4.4444e-02,  2.3040e-02, -9.8963e-03,\n",
       "         -1.8799e-02, -3.1167e-02,  3.7424e-02, -9.6440e-02, -3.9466e-03,\n",
       "         -3.9369e-02,  5.1334e-03, -5.2730e-02,  1.5799e-04, -9.2566e-02,\n",
       "         -1.0396e-01, -3.2632e-02, -7.1766e-04, -2.7439e-02, -5.2765e-02,\n",
       "          8.3258e-02, -2.7060e-02,  1.0114e-01, -3.6279e-02,  1.0416e-03,\n",
       "         -1.0183e-01, -4.8936e-02, -1.8019e-02, -4.8425e-04,  8.8238e-02,\n",
       "         -1.6195e-02, -1.6646e-01, -1.0474e-01,  5.1248e-02,  5.5006e-02,\n",
       "         -1.5823e-01,  4.7771e-02,  2.1546e-01, -1.4640e-02, -2.9511e-01,\n",
       "         -3.7870e-02, -6.5958e-02,  1.1735e-01, -1.4349e-02, -3.4509e-02,\n",
       "          8.1380e-02,  3.9554e-02,  8.4236e-02,  5.0764e-02, -1.2108e-02,\n",
       "         -1.9913e-02, -8.0047e-02,  1.6560e-02, -1.6174e-02, -6.9749e-02,\n",
       "          1.1547e-02, -1.6650e-01, -4.5148e-02,  3.6935e-02, -8.2345e-02,\n",
       "          1.9310e-02,  2.3235e-03, -1.3523e-02, -7.8357e-02, -1.4665e-02,\n",
       "          3.8211e-02, -4.3566e-02,  1.3519e-01,  1.5452e-02,  7.9634e-02,\n",
       "          7.8005e-02, -8.8433e-02,  1.1904e-01,  7.9820e-02,  5.5434e-02,\n",
       "         -2.5875e-02, -6.0228e-02, -4.2529e-02, -4.0716e-04,  4.4076e-02,\n",
       "          2.5519e-02, -2.7115e-02,  2.0026e-02,  6.8287e-02, -1.0144e-01,\n",
       "         -7.9399e-02, -1.0233e-01,  3.4188e-02,  2.5903e-02,  6.3533e-02,\n",
       "          3.7759e-01, -1.2014e-01, -4.4943e-02,  1.7438e-01,  3.0236e-02,\n",
       "         -6.0608e-02, -1.0860e-01,  2.6856e-01, -5.3128e-02, -3.6286e-02,\n",
       "          5.7280e-02, -3.3064e-02,  3.8055e-02, -5.0045e-02,  6.8525e-02,\n",
       "         -5.0010e-02,  3.1136e-02,  1.1439e-01, -5.8169e-02, -2.4297e-02,\n",
       "         -3.1782e-02,  3.9725e-02,  9.5029e-02, -6.5586e-02, -4.1484e-02,\n",
       "         -6.0688e-02,  3.4179e-02,  6.4377e-02, -4.4197e-03,  5.3401e-02,\n",
       "         -1.3292e-02, -4.2312e-02,  3.2787e-02, -6.9254e-02,  3.4910e-02,\n",
       "          6.6547e-02, -3.8600e-02,  3.4962e-02, -4.2647e-02, -8.3170e-02,\n",
       "         -7.4400e-02,  1.6588e-01, -3.4367e-02, -6.2182e-02, -1.0138e-01,\n",
       "         -3.6010e-02, -3.5842e-02,  1.7982e-01, -1.1931e-02, -3.6295e-02,\n",
       "         -7.5139e-02,  7.2719e-02,  1.0476e-02, -1.5399e-02, -2.5121e-02,\n",
       "          2.9032e-02, -1.7308e-02,  4.9105e-02,  8.6835e-02, -5.8784e-02,\n",
       "         -1.2898e-01, -1.5214e-04,  6.4945e-02,  1.1120e-01,  1.6281e-01,\n",
       "         -3.9178e-02, -4.6999e-02, -1.1932e-01,  2.6953e-02, -2.0424e-02,\n",
       "         -3.9047e-02, -7.4101e-02,  1.5744e-02,  8.1641e-03,  3.3094e-02,\n",
       "         -4.3857e-02,  9.7628e-02,  6.3132e-02,  2.7319e-02,  2.0149e-02,\n",
       "         -1.1529e-01,  1.4811e-01,  1.4215e-02,  4.1059e-02,  2.5435e-02,\n",
       "          2.3034e-02,  3.3170e-02, -1.0846e-01,  4.8453e-02,  6.0434e-02,\n",
       "          1.7116e-02,  6.0217e-03, -1.0375e-01, -1.0973e-02,  7.6897e-02,\n",
       "         -1.6429e-01,  6.7194e-02, -8.3775e-02, -1.9333e-02,  2.7411e-01,\n",
       "         -2.4837e-02,  1.1034e-01,  6.7033e-02, -1.4012e-02, -1.6114e-01,\n",
       "         -1.2419e-02, -1.5749e-02, -6.2492e-02,  9.2768e-02, -5.7087e-02,\n",
       "         -1.0662e-02,  2.9012e-02,  9.6328e-03, -5.0828e-02, -1.5509e-02,\n",
       "         -3.9571e-02, -4.2315e-02, -1.4126e-02,  7.5109e-02,  4.3042e-02,\n",
       "         -2.1899e-02,  2.3254e-02,  1.9825e-02, -6.4979e-02,  9.3419e-02,\n",
       "          2.3186e-02,  3.0592e-02, -1.9917e-02,  1.2935e-01,  7.8237e-02,\n",
       "         -8.3063e-02,  2.1891e-02,  1.3188e-02, -2.6292e-02,  1.9779e-02,\n",
       "          1.8277e-01,  9.8614e-02,  2.4616e-02,  1.0370e-02,  2.2563e-02,\n",
       "          6.8695e-02,  6.0395e-03, -3.5510e-02, -1.7260e-02,  5.2292e-03,\n",
       "          6.8487e-02, -4.0594e-03,  7.7013e-02, -9.4007e-02, -3.0697e-01,\n",
       "          3.7714e-02, -5.5181e-02,  6.5153e-02,  1.1127e-01, -8.6877e-02,\n",
       "         -5.8493e-03,  2.2207e-02, -3.1880e-02, -4.0784e-02,  2.1419e-01,\n",
       "          1.8487e-01,  1.0750e-01,  5.1413e-02,  5.7069e-02, -7.4325e-02,\n",
       "         -5.7651e-02, -3.6596e-02,  6.2743e-02, -3.7298e-02, -2.6666e-02,\n",
       "         -5.5768e-02,  9.1048e-02,  1.5531e-02, -2.2273e-02,  9.1851e-03,\n",
       "         -2.0006e-02,  5.5091e-02,  4.0433e-02, -2.1639e-02, -1.6041e-01,\n",
       "          1.1906e-02, -1.1633e-01,  3.0765e-02, -4.7691e-02,  9.7332e-03,\n",
       "          9.2097e-03,  8.0043e-02, -6.0489e-02,  2.5849e-02,  9.4553e-02,\n",
       "         -1.3848e-01,  1.4588e-01, -6.9805e-03, -8.9645e-02,  1.0498e-02,\n",
       "          9.9598e-03,  2.8871e-02,  6.8843e-02,  3.2314e-02, -9.0252e-02,\n",
       "          9.9437e-03,  3.9026e-02,  4.3197e-02, -4.3128e-02,  9.9320e-02,\n",
       "          6.5263e-02,  4.0411e-02,  6.8559e-02,  4.8457e-02,  2.2651e-02,\n",
       "         -2.2328e-02, -1.5794e-01,  1.6847e-02,  2.4490e-02, -6.2156e-02,\n",
       "         -4.9845e-02,  1.5687e-02, -6.0497e-02, -1.0647e-04,  5.1318e-02,\n",
       "          1.2742e-01,  6.2152e-02, -9.9476e-02, -1.0559e-01,  1.2395e-01,\n",
       "         -1.0327e-01,  8.1657e-03,  2.9166e-02,  1.9717e-02,  2.4014e-03,\n",
       "         -3.4124e-02, -1.4492e-01, -1.9019e-02,  1.7371e-01, -7.4911e-02,\n",
       "          7.8430e-05, -1.2862e-01, -2.0957e-02,  6.2929e-02, -3.0254e-02,\n",
       "         -1.4265e-01, -1.9421e-02,  3.0340e-02,  2.9835e-02, -5.2878e-02,\n",
       "          9.9328e-02, -4.8742e-02,  5.2884e-03, -1.0477e-01,  3.5970e-02,\n",
       "          1.9931e-02,  3.3825e-02,  5.8202e-02,  1.1659e-03,  3.6246e-02,\n",
       "         -4.4031e-02, -1.8040e-03,  8.9821e-03, -1.1713e-01,  3.5065e-02,\n",
       "         -3.9026e-02,  4.8170e-03, -6.1493e-02, -3.7921e-02,  8.6163e-02,\n",
       "         -4.8729e-02, -1.3953e-02, -2.6947e-02,  2.5511e-02,  7.2134e-02,\n",
       "         -2.8559e-02,  1.2097e-02, -1.4424e-02,  1.2098e-01, -5.3285e-02,\n",
       "          1.2656e-01,  9.7585e-02, -3.3430e-02, -4.9453e-02, -1.1830e-02,\n",
       "          1.9620e-02,  5.5817e-03, -2.8411e-02, -2.9561e-02,  9.5337e-03,\n",
       "         -3.1542e-02, -3.6050e-02,  6.7173e-02, -2.5398e-02,  7.5535e-02,\n",
       "         -6.4036e-02,  1.6638e-02,  2.9933e-01, -1.0035e-02, -2.2228e-02,\n",
       "         -1.2460e-01,  4.5772e-02, -1.1685e-02,  5.3740e-02, -1.4982e-01,\n",
       "          9.6976e-02,  1.0097e-01,  1.9107e-01, -1.5956e-02, -4.8992e-02,\n",
       "         -1.4865e-01, -1.2197e-01,  1.3584e-02,  9.5096e-02, -1.8245e-02,\n",
       "          3.9432e-02, -4.8589e-02]),\n",
       " 'emb_s': tensor([-2.0725e-01,  2.6102e-01, -3.1507e-01,  8.3587e-01,  4.8850e-01,\n",
       "         -6.3994e-01, -7.5143e-01, -5.9087e-01,  5.1628e-01, -6.8361e-02,\n",
       "          2.9725e-01, -1.1876e-01,  1.7588e+00,  8.7277e-02, -4.0718e-01,\n",
       "         -7.8154e-01,  6.2611e-01,  1.2017e-01,  5.5271e-01,  1.4136e-02,\n",
       "          4.0117e-01, -1.1450e-01, -2.6780e-01, -1.7233e-01,  5.2736e-01,\n",
       "         -2.7158e-01,  2.3472e-01,  3.9486e-01, -1.6550e-01,  5.7861e-01,\n",
       "          7.1882e-01, -6.4597e-01,  4.5526e-01,  9.9873e-01,  5.4534e-01,\n",
       "          1.7278e-01, -1.3204e-02, -2.7220e-01,  5.5559e-01, -1.1505e-01,\n",
       "          3.5618e-01,  6.4391e-01,  3.2935e-01, -3.6195e-01,  9.2969e-02,\n",
       "         -5.8798e-01,  2.5618e-01,  5.4398e-01, -3.2524e-01, -4.9756e-01,\n",
       "          3.3083e-01,  3.5666e-02,  5.1678e-01, -1.1688e-01, -1.5146e+00,\n",
       "         -1.1744e+00,  1.5399e-01,  1.2377e-01, -3.3949e-01,  6.5830e-01,\n",
       "          1.5328e-01,  4.5321e-01, -1.3738e-01,  6.9984e-01,  6.9656e-01,\n",
       "         -6.3839e-01,  3.7439e-01, -6.1109e-01, -5.5451e-01, -2.6570e-01,\n",
       "         -4.9909e-01, -1.1671e-01,  2.8246e-01, -1.0547e-01, -5.8458e-01,\n",
       "         -4.6408e-01, -2.0649e-01,  8.1583e-02,  1.4749e-02, -2.1466e-01,\n",
       "          5.8480e-01,  1.0606e+00,  4.6433e-01,  1.0515e+00,  1.3562e-01,\n",
       "         -4.8992e-01, -5.3609e-01,  6.5167e-01,  3.7441e-01,  3.5656e-01,\n",
       "          2.7589e-01,  3.1376e-02, -8.9980e-01,  5.1380e-01,  9.4258e-02,\n",
       "          3.1568e-01,  2.7062e-01, -8.8864e-02,  2.7561e-01, -5.9197e-01,\n",
       "         -1.8863e-01, -1.3779e+00, -1.3194e-01, -4.9876e-01, -7.1315e-01,\n",
       "          2.7032e-01, -2.0776e-01, -5.1200e-01,  7.2737e-01, -2.7168e-01,\n",
       "         -4.4578e-01, -1.0435e-01,  6.7871e-01, -8.5923e-01,  7.1700e-01,\n",
       "         -5.7563e-01,  8.1763e-01, -2.4141e-01, -3.5374e-01, -5.5538e-01,\n",
       "         -8.4620e-02,  1.9556e-01, -2.2226e-01, -3.3931e-01,  8.4979e-01,\n",
       "         -3.9658e-01, -4.0070e-03, -4.4418e-01,  8.3032e-01, -7.7560e-01,\n",
       "         -1.4967e-01, -5.4121e-01, -2.7921e-01,  4.4844e-01, -8.2897e-01,\n",
       "          5.2355e-01,  3.6990e-01,  9.2462e-01, -1.9225e-01,  3.1491e-01,\n",
       "          3.2927e-01, -8.6695e-01,  7.7647e-02,  9.8702e-01,  4.9594e-01,\n",
       "         -1.1805e+00,  3.0373e-01,  3.0943e-01,  3.2184e-02,  6.2178e-01,\n",
       "          7.3697e-01, -4.9823e-01, -2.7720e-01, -7.7530e-02,  5.9787e-01,\n",
       "         -2.5143e-01, -7.3300e-01, -1.4443e-01, -3.9959e-01,  2.2938e-01,\n",
       "          2.8318e-01,  6.4545e-01,  3.0212e-01, -2.8743e-01,  5.9050e-01,\n",
       "         -2.9958e-01, -5.0040e-01, -1.1670e-01, -4.7003e-01, -5.6714e-01,\n",
       "         -1.5792e-01, -4.9311e-01, -4.4514e-01,  2.6988e-01,  5.4494e-01,\n",
       "          1.0006e-01, -1.7502e-01, -1.3466e-01, -2.0585e-01, -7.8714e-01,\n",
       "         -4.3925e-01, -5.3937e-01, -7.3420e-02,  5.9691e-01, -1.8315e-01,\n",
       "         -1.7003e-01, -4.9947e-01, -5.1508e-01,  6.6192e-01, -2.5528e-01,\n",
       "         -1.8459e-01,  5.9215e-01,  1.7035e-01,  2.0597e-01,  1.6282e-02,\n",
       "         -1.3279e-01,  5.2900e-02,  3.9056e-01, -6.9850e-01, -5.7541e-01,\n",
       "          3.9566e-01, -5.6473e-02,  3.1108e-01,  4.1392e-01,  9.6250e-02,\n",
       "         -1.2104e+00, -1.6429e-01,  7.6020e-01,  8.0819e-01,  3.0041e-01,\n",
       "          1.1558e-01,  5.7787e-01, -6.0263e-01,  2.8495e-01, -4.3124e-01,\n",
       "         -1.6046e-01,  3.7165e-01,  4.2478e-01, -4.7087e-01,  5.9178e-01,\n",
       "          5.7878e-01, -1.1764e+00,  5.2130e-01,  1.0246e-01, -1.2969e-01,\n",
       "          1.8780e-01,  4.2372e-02,  4.0215e-02,  5.9032e-02,  5.3592e-01,\n",
       "          6.3632e-01,  4.2803e-01, -5.0854e-01,  8.7992e-01, -5.1132e-01,\n",
       "         -7.0018e-01,  2.6741e-01,  2.2500e-01, -2.3592e-01, -2.1799e+00,\n",
       "         -1.4419e-01,  5.7405e-01,  2.5839e-01, -3.7464e-01,  3.5895e-01,\n",
       "         -5.7615e-01, -4.9535e-01,  5.4753e-01, -5.7832e-01, -5.6601e-02,\n",
       "          2.7564e-01, -4.5467e-01,  6.4859e-01, -5.6544e-01,  1.2574e-02,\n",
       "          9.3059e-02, -6.2620e-01,  2.6484e-01,  1.8644e-01,  4.1433e-01,\n",
       "          1.6593e-01, -8.8943e-01, -1.5734e-01, -7.1541e-01, -2.8062e-01,\n",
       "          1.1601e-01,  2.0847e+00, -2.2626e-01, -2.8766e-01, -3.1195e-01,\n",
       "         -7.4394e-01,  3.9325e-02, -6.2127e-01,  1.7096e-01,  1.5377e-01,\n",
       "         -1.0153e-01, -9.6099e-01,  4.8546e-01, -8.2383e-01, -2.5522e-01,\n",
       "         -3.7565e-01,  1.0701e+00, -1.9244e-01, -2.7714e-01, -5.0849e-01,\n",
       "          8.4286e-01, -1.1361e+00, -1.3291e-02, -6.4395e-01,  3.6877e-01,\n",
       "          9.6104e-01,  3.8788e-01, -1.4109e-01,  6.0203e-01,  9.0541e-01,\n",
       "          1.4791e-01,  6.5774e-01,  3.1733e-01,  5.1748e-01,  4.5529e-01,\n",
       "         -8.2208e-02,  1.6441e-01,  4.0824e-01, -1.0411e+00, -3.6490e-01,\n",
       "          8.1186e-02,  1.7846e+00,  7.9321e-01, -4.1410e-01,  4.2081e-01,\n",
       "         -7.7440e-01, -3.2004e-01, -8.9184e-01,  8.6106e-01, -1.2159e-01,\n",
       "         -2.5457e-01, -3.9134e-01,  4.9792e-01, -3.7375e-02,  5.9574e-01,\n",
       "         -4.2979e-02,  6.0150e-01, -3.2757e-01, -1.0887e+00,  2.1587e-01,\n",
       "          1.5561e-01,  1.0137e+00, -1.6352e-01,  9.6127e-01, -6.3381e-02,\n",
       "          3.0754e-02,  2.7663e-01, -5.1426e-01,  8.2222e-01, -1.4060e+00,\n",
       "          3.9117e-01, -5.7288e-01, -7.8673e-01,  5.3626e-01,  2.2812e-01,\n",
       "         -4.8212e-01,  2.5932e-01, -9.2575e-02, -3.6139e-01,  9.7493e-01,\n",
       "         -9.7172e-01, -5.7932e-02,  2.2453e-01, -3.7408e-01,  5.7708e-01,\n",
       "          5.6632e-01, -8.9455e-01,  6.0555e-01,  1.4383e-01, -3.8812e-01,\n",
       "         -2.7057e-01, -1.0069e-01, -2.6924e-01, -5.5911e-01, -5.4979e-01,\n",
       "         -2.5508e-01,  5.6940e-01,  3.7956e-01, -4.1470e-01,  8.0896e-01,\n",
       "          2.7234e-01, -2.6054e-01, -6.9817e-02,  1.7661e-01, -1.2751e-01,\n",
       "          1.1319e+00,  1.9770e-01, -4.7525e-01, -6.1395e-01,  1.8738e-01,\n",
       "         -7.2507e-01,  7.8103e-01, -1.1166e+00, -4.3106e-02,  6.0008e-01,\n",
       "          1.0267e+00,  7.2568e-01,  1.2233e-01,  5.2052e-01, -5.3036e-01,\n",
       "          4.5382e-01,  4.5921e-01, -8.8798e-01,  6.3333e-01,  4.7955e-03,\n",
       "         -1.7587e-01, -5.8433e-01, -4.7753e-01,  7.2445e-01,  3.5892e-01,\n",
       "         -1.0631e-01,  4.6534e-01,  2.9662e-01, -3.2147e-02, -9.8559e-01,\n",
       "          7.3077e-01,  3.9327e-01,  5.0388e-01,  6.5678e-01,  6.3120e-01,\n",
       "          8.0688e-01,  9.9041e-02,  8.7787e-01, -1.9035e-01, -2.8576e-01,\n",
       "          9.6830e-01, -9.5538e-03,  5.5248e-01, -3.0793e-01,  1.5543e-01,\n",
       "         -1.2760e-01, -3.9508e-01,  1.5568e-01,  3.0971e-01,  6.2353e-02,\n",
       "         -4.4788e-01,  4.2404e-01,  2.7549e-01,  5.0791e-01,  4.6748e-01,\n",
       "         -1.2680e+00, -3.6239e-01, -3.1712e-01,  3.9468e-02, -6.9484e-01,\n",
       "         -4.5049e-01,  8.8666e-02,  1.2251e-01, -5.4855e-01,  1.5481e-01,\n",
       "         -4.3626e-01,  3.9439e-01,  4.3928e-01, -3.3348e-01,  3.8968e-01,\n",
       "         -2.2372e-01,  1.8639e-02,  4.0683e-01, -1.0031e+00, -8.1237e-01,\n",
       "         -1.9546e-01, -9.3164e-01,  4.1596e-01, -2.6168e-01, -2.5343e-01,\n",
       "          2.6102e-01,  1.8453e-01,  2.3401e-01, -1.5538e-01,  3.1819e-01,\n",
       "         -6.5370e-01,  8.1327e-01, -5.8795e-01,  7.4632e-01, -1.5117e+00,\n",
       "          9.7511e-01,  7.3834e-01, -6.1369e-01, -5.3132e-01, -9.8202e-01,\n",
       "         -1.4616e+00,  3.1581e-02, -9.5353e-01,  3.9315e-01, -4.9532e-02,\n",
       "         -9.6607e-01, -2.3600e-01, -7.6846e-02, -1.4461e-02,  9.8638e-01,\n",
       "          8.1078e-01, -1.2246e-01,  3.6709e-01,  8.7005e-01, -5.7231e-01,\n",
       "          2.7495e-01, -1.1300e-01, -2.4813e-01,  3.1790e-01,  4.2152e-01,\n",
       "          6.0813e-01, -1.2679e+00,  3.3003e-01,  4.7479e-01, -4.2719e-01,\n",
       "         -4.2554e-02,  1.8922e-01,  2.8110e-01, -1.9591e-01,  6.0026e-01,\n",
       "          3.6542e-01,  1.0114e-01, -1.0731e+00,  7.3067e-01,  4.1632e-01,\n",
       "         -5.1549e-02, -2.2158e-01, -4.8697e-01,  5.9412e-03, -5.5131e-01,\n",
       "          3.5592e-01, -9.8708e-01,  3.8623e-02,  6.1434e-01, -1.4012e-01,\n",
       "          1.6361e+00, -8.6231e-01, -2.9435e-01, -5.0515e-01,  6.9672e-02,\n",
       "          1.7541e-01, -7.0527e-01,  7.7930e-01,  1.7658e-01, -5.2174e-01,\n",
       "         -4.6640e-01,  3.5951e-03, -6.9753e-01, -3.7453e-01,  7.2904e-01,\n",
       "         -4.7624e-01,  2.6309e-01, -6.1551e-01,  3.0962e-01, -4.0662e-01,\n",
       "          4.6788e-01, -9.3924e-01,  3.6588e-01, -1.3392e+00, -9.1762e-01,\n",
       "          4.9194e-02, -4.5707e-01,  3.2241e-01,  6.7524e-01,  6.0103e-02,\n",
       "         -1.9816e-01, -4.8693e-01,  6.3202e-01, -8.3099e-02,  5.8734e-01,\n",
       "         -1.7674e-01,  4.4599e-01, -4.5060e-01,  2.7145e-03,  7.0726e-02,\n",
       "          9.3151e-03, -3.9435e-01, -4.1750e-01,  9.7098e-01, -1.0903e+00,\n",
       "          9.5262e-01,  2.4099e-01, -9.3019e-02,  2.4784e-01,  3.4796e-02,\n",
       "          4.9284e-02, -5.4253e-01,  1.2601e-01,  8.3309e-01,  2.2455e-02,\n",
       "          1.8405e-01,  2.2224e-01,  2.0145e-01, -8.8612e-01,  2.4603e-01,\n",
       "         -9.1875e-01,  5.7503e-01,  5.0084e-01, -5.3278e-01,  3.0830e-01,\n",
       "          2.1169e-02, -7.0614e-01, -4.9573e-01,  3.7954e-01, -7.1672e-01,\n",
       "         -7.8447e-02, -1.2774e-01, -6.7302e-01,  1.2047e+00,  6.1021e-01,\n",
       "          2.4241e-01,  4.4419e-01, -3.6295e-01, -2.8394e+00,  7.2266e-01,\n",
       "         -1.9887e-01, -7.2032e-01, -1.4615e-01,  4.5094e-01, -2.1167e-01,\n",
       "         -3.9123e-02,  2.9038e-01, -3.0248e-01,  2.8823e-01, -9.1333e-01,\n",
       "          8.0442e-01, -5.9784e-01, -3.8545e-01,  3.1294e-01,  7.3882e-02,\n",
       "         -4.9105e-01,  4.8075e-01,  2.6525e-01,  8.9801e-02,  5.4713e-01,\n",
       "         -2.6427e-01, -9.8460e-02, -5.4743e-01, -7.1952e-02, -7.8000e-01,\n",
       "          6.7256e-01,  4.3879e-01,  6.3478e-01, -5.1999e-02, -2.8653e-01,\n",
       "          7.9294e-01,  3.2759e-01, -7.1498e-01, -2.9885e-01, -1.8563e-01,\n",
       "         -8.7339e-03, -3.7416e-01,  4.1840e-01, -3.0785e-01, -8.5067e-01,\n",
       "         -7.3874e-01,  6.4717e-01,  9.7834e-02,  2.2335e-01, -9.9007e-03,\n",
       "          3.7545e-01, -3.7596e-01, -5.5932e-01,  1.8604e-01,  5.1073e-01,\n",
       "         -1.3404e+00,  3.7311e-02, -2.1221e-01,  9.7821e-01,  1.9432e-02,\n",
       "          4.2228e-01,  4.1574e-01, -6.8168e-01,  8.9861e-01,  7.2153e-01,\n",
       "         -2.6494e-01,  2.1635e-01, -6.8400e-01, -2.8261e-01,  3.0895e-01,\n",
       "         -2.1344e-01, -4.5190e-01,  1.3367e-01,  5.3012e-01, -5.2834e-01,\n",
       "         -1.2102e+00,  9.9950e-01,  4.3177e-01, -8.3371e-02,  3.1886e-01,\n",
       "          1.3641e-01, -6.8590e-01,  8.2550e-01, -5.0065e-01, -9.4570e-01,\n",
       "         -2.2668e-01,  7.0318e-01, -3.8000e-01, -4.0919e-01, -1.8005e-01,\n",
       "          3.5222e-01,  4.1109e-01,  2.3968e-01, -6.8925e-01, -1.1366e+00,\n",
       "          2.8763e-01,  8.8721e-02,  3.8610e-02, -9.0584e-02, -1.0197e-01,\n",
       "          4.4071e-01,  7.6164e-01, -1.8687e-01,  5.0908e-01, -5.5514e-01,\n",
       "          1.5756e-02,  9.7385e-01,  3.6214e-01, -1.8044e-01, -1.0712e+00,\n",
       "          4.4700e-01, -1.5972e-02, -5.4610e-01,  3.8047e-01,  4.3752e-01,\n",
       "          3.8354e-01, -4.1534e-01, -2.3976e-02, -2.4879e-01,  5.1561e-01,\n",
       "         -1.1371e+00,  1.0967e-01, -8.9589e-01, -2.6983e-01, -1.1794e-01,\n",
       "          5.6275e-01, -8.4937e-02,  6.4787e-01, -4.2984e-01, -2.3204e-01,\n",
       "          2.8445e-02,  2.6864e-01,  4.4841e-01, -3.7148e-01, -5.1237e-01,\n",
       "          6.7701e-01, -3.6862e-02, -1.2052e+00,  3.1811e-01,  1.3230e-01,\n",
       "          2.6716e-01,  6.8290e-01,  3.5148e-01,  1.0096e+00, -1.3132e+00,\n",
       "         -2.0735e-01,  4.2441e-01, -3.8284e-01,  2.4456e-01,  3.0366e-01,\n",
       "         -4.2473e-02,  8.4693e-01, -1.5813e-01, -4.1449e-01, -7.9765e-01,\n",
       "         -1.9273e-01, -2.4689e-01, -2.5209e-01,  9.3971e-01,  5.0708e-01,\n",
       "          4.6721e-01, -2.1001e-01,  3.8548e-01, -8.6884e-01, -1.0059e+00,\n",
       "          2.8833e-01,  2.1422e-01,  1.5579e-01,  3.1693e-01, -5.0289e-01,\n",
       "         -1.3992e-01, -1.2934e-01,  5.1765e-01,  2.1770e-02,  3.5978e-01,\n",
       "          2.2580e-01, -2.5153e-01,  1.6937e-01,  3.4708e-01,  1.1599e+00,\n",
       "         -7.8593e-01, -4.5631e-01,  6.0976e-01])}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "285a438f-6e37-40d1-beb8-98cf8805b239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:27.565573Z",
     "iopub.status.busy": "2024-10-22T06:53:27.564328Z",
     "iopub.status.idle": "2024-10-22T06:53:27.587045Z",
     "shell.execute_reply": "2024-10-22T06:53:27.586055Z",
     "shell.execute_reply.started": "2024-10-22T06:53:27.565512Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = emb_s.shape[1]\n",
    "output_dim = emb_g.shape[1]\n",
    "model = AlignmentModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0f446bae-baa1-47eb-8ae1-3301ad67037b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:28.117863Z",
     "iopub.status.busy": "2024-10-22T06:53:28.116651Z",
     "iopub.status.idle": "2024-10-22T06:53:28.129921Z",
     "shell.execute_reply": "2024-10-22T06:53:28.128897Z",
     "shell.execute_reply.started": "2024-10-22T06:53:28.117785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlignmentModel(\n",
       "  (linear): Linear(in_features=768, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "03e72a83-7362-419d-92b7-b23721d4128b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:28.820029Z",
     "iopub.status.busy": "2024-10-22T06:53:28.819108Z",
     "iopub.status.idle": "2024-10-22T06:53:28.837134Z",
     "shell.execute_reply": "2024-10-22T06:53:28.835859Z",
     "shell.execute_reply.started": "2024-10-22T06:53:28.819987Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=1,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "         remove_unused_columns=False, #very important.\n",
    "    use_mps_device=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2bbdc8f9-c566-4017-aed7-b004c215777b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:30.363551Z",
     "iopub.status.busy": "2024-10-22T06:53:30.361770Z",
     "iopub.status.idle": "2024-10-22T06:53:30.379786Z",
     "shell.execute_reply": "2024-10-22T06:53:30.377804Z",
     "shell.execute_reply.started": "2024-10-22T06:53:30.363498Z"
    }
   },
   "outputs": [],
   "source": [
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def forward(self, aligned_emb_s, emb_g):\n",
    "        cos_sim = nn.functional.cosine_similarity(aligned_emb_s, emb_g, dim=-1)\n",
    "        loss = 1 - cos_sim.mean()\n",
    "        return loss\n",
    "        \n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        print(inputs.keys())\n",
    "        emb_s = inputs['emb_s']\n",
    "        emb_g = inputs['emb_g']\n",
    "        \n",
    "        aligned_emb_s = model(emb_s)\n",
    "        loss_fn = CosineSimilarityLoss()\n",
    "        loss = loss_fn(aligned_emb_s, emb_g)\n",
    "        \n",
    "        return (loss, aligned_emb_s) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8fd438a6-b925-48a4-aeca-d9c7683356c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:31.904305Z",
     "iopub.status.busy": "2024-10-22T06:53:31.903120Z",
     "iopub.status.idle": "2024-10-22T06:53:31.929911Z",
     "shell.execute_reply": "2024-10-22T06:53:31.929180Z",
     "shell.execute_reply.started": "2024-10-22T06:53:31.904253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create custom trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "57733f39-04de-4b78-862f-36648c5390d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:47.007305Z",
     "iopub.status.busy": "2024-10-22T06:53:47.005204Z",
     "iopub.status.idle": "2024-10-22T06:53:47.298980Z",
     "shell.execute_reply": "2024-10-22T06:53:47.298548Z",
     "shell.execute_reply.started": "2024-10-22T06:53:47.007022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['emb_g', 'emb_s'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bj/qp6k2wl11h5gpn8j4hg0tgf40000gn/T/ipykernel_47549/3274619231.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'emb_g': torch.tensor(self.emb_g[idx], dtype=torch.float32),\n",
      "/var/folders/bj/qp6k2wl11h5gpn8j4hg0tgf40000gn/T/ipykernel_47549/3274619231.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'emb_s': torch.tensor(self.emb_s[idx], dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n",
      "dict_keys(['emb_g', 'emb_s'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=0.13779906034469605, metrics={'train_runtime': 0.1395, 'train_samples_per_second': 107.559, 'train_steps_per_second': 107.559, 'total_flos': 0.0, 'train_loss': 0.13779906034469605, 'epoch': 5.0})"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d4957d35-bdaa-42f5-a9b6-f0ad21214e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:50.042841Z",
     "iopub.status.busy": "2024-10-22T06:53:50.042182Z",
     "iopub.status.idle": "2024-10-22T06:53:50.049002Z",
     "shell.execute_reply": "2024-10-22T06:53:50.047935Z",
     "shell.execute_reply.started": "2024-10-22T06:53:50.042797Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "39112654-0627-46d7-93ba-ae6926a00130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:50.412070Z",
     "iopub.status.busy": "2024-10-22T06:53:50.410929Z",
     "iopub.status.idle": "2024-10-22T06:53:50.425466Z",
     "shell.execute_reply": "2024-10-22T06:53:50.424393Z",
     "shell.execute_reply.started": "2024-10-22T06:53:50.412024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlignmentModel(\n",
       "  (linear): Linear(in_features=768, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b3c1db1b-5681-4138-aa55-78df8764b97f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:50.810783Z",
     "iopub.status.busy": "2024-10-22T06:53:50.809248Z",
     "iopub.status.idle": "2024-10-22T06:53:50.830189Z",
     "shell.execute_reply": "2024-10-22T06:53:50.829457Z",
     "shell.execute_reply.started": "2024-10-22T06:53:50.810704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2073,  0.2610, -0.3151,  ..., -0.7859, -0.4563,  0.6098],\n",
       "        [-0.1964,  0.8787, -0.4009,  ..., -0.8158, -0.4921,  0.8882],\n",
       "        [-0.1370,  0.2270, -0.0974,  ..., -0.5315, -0.5712,  0.6356]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "455a8779-fb0c-4b8b-ab5b-3872f5c25e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:51.538511Z",
     "iopub.status.busy": "2024-10-22T06:53:51.537416Z",
     "iopub.status.idle": "2024-10-22T06:53:51.553646Z",
     "shell.execute_reply": "2024-10-22T06:53:51.552337Z",
     "shell.execute_reply.started": "2024-10-22T06:53:51.538435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "08a29ac5-a6ff-4f83-9a51-9c9932009d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:52.026957Z",
     "iopub.status.busy": "2024-10-22T06:53:52.025918Z",
     "iopub.status.idle": "2024-10-22T06:53:52.048528Z",
     "shell.execute_reply": "2024-10-22T06:53:52.047438Z",
     "shell.execute_reply.started": "2024-10-22T06:53:52.026908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlignmentModel(\n",
       "  (linear): Linear(in_features=768, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "emb_s = emb_s.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5c350d22-a992-47db-8e55-11dacf5fb861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:53.950431Z",
     "iopub.status.busy": "2024-10-22T06:53:53.948780Z",
     "iopub.status.idle": "2024-10-22T06:53:53.963427Z",
     "shell.execute_reply": "2024-10-22T06:53:53.961799Z",
     "shell.execute_reply.started": "2024-10-22T06:53:53.950360Z"
    }
   },
   "outputs": [],
   "source": [
    "aligned_emb_s =model(emb_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "10c0ad27-2133-4bb4-8507-115253009f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:54.294732Z",
     "iopub.status.busy": "2024-10-22T06:53:54.293789Z",
     "iopub.status.idle": "2024-10-22T06:53:54.315651Z",
     "shell.execute_reply": "2024-10-22T06:53:54.310944Z",
     "shell.execute_reply.started": "2024-10-22T06:53:54.294686Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_g = encoder_decoder.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fa66e53c-db99-490d-8813-b1a7a63be48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:54.605905Z",
     "iopub.status.busy": "2024-10-22T06:53:54.604855Z",
     "iopub.status.idle": "2024-10-22T06:53:54.619403Z",
     "shell.execute_reply": "2024-10-22T06:53:54.618476Z",
     "shell.execute_reply.started": "2024-10-22T06:53:54.605860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_emb_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5ef177d3-4755-4451-91fc-696987189cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T06:53:55.188715Z",
     "iopub.status.busy": "2024-10-22T06:53:55.187824Z",
     "iopub.status.idle": "2024-10-22T06:53:56.475198Z",
     "shell.execute_reply": "2024-10-22T06:53:56.474751Z",
     "shell.execute_reply.started": "2024-10-22T06:53:55.188674Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512])\n",
      "                                                \n"
     ]
    }
   ],
   "source": [
    "aligned_emb = aligned_emb_s.unsqueeze(0)\n",
    "print(aligned_emb.shape)\n",
    "# Create a named tuple to pass encoder outputs manually\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "encoder_outputs = BaseModelOutput(last_hidden_state=aligned_emb)\n",
    "# print(encoder_outputs.shape)\n",
    "\n",
    "# Provide initial decoder input IDs (start token)\n",
    "decoder_input_ids = torch.tensor([[encoder_decoder.config.decoder_start_token_id]])\n",
    "\n",
    "# Generate text based on aligned embeddings\n",
    "decoder_outputs = encoder_decoder.generate(\n",
    "    encoder_outputs=encoder_outputs,\n",
    "    decoder_input_ids=decoder_input_ids,\n",
    "    max_length=50,  # Limit the generation length\n",
    "    num_beams=5     # Beam search for better results (optional)\n",
    ")\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_text = encoder_decoder_tokenizer.decode(decoder_outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567de32f-5087-4e29-bd2e-4a4f9ec742f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fewshotinversion",
   "language": "python",
   "name": "fewshot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
